---
title: "Tarea 2 EPS"
author: "Federico Daverio"
output:
  html_document:
    toc: yes
    toc_depth: 3
    number_sections: no
    theme: united
    highlight: tango
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
options(scipen=999) 
memory.limit(size=56000)
library(pacman)
p_load(Hmisc, mfx,readr, dplyr,haven, margins,MASS, stargazer, AER)
library(tidyverse)
library(reticulate)
library(sandwich)
library(readr)
library(sandwich)
library(clubSandwich)
library(modelsummary)
library(estimatr)
library(lmtest)
library(formattable)
library(car)
library(nnet)
library(nlsr)
library(janitor)
library(data.table)
```

# Ejercicio 1
*En la Sesión 7 introducimos los datos de una intervención en Marruecos en la que un producto financiero fue ofrecido de manera aleatoria, pero la adopción del producto obedeció a un proceso de selección. Para este problema use la base crepon_morocco_analysis.csv, que tiene un subconjunto de los datos usados en dicha sesión ya listos para su análisis. La variable treatment contiene la variable de tratamiento y la variable client es la variable de adopción. En esta pregunta nos enfocaremos en el efecto causal de la adopción en el gasto total de los hogares, expense_total.*


## Inciso A
*Primero mostraremos cómo el estimador de Wald es equivalente al estimador de VI cuando no hay controles y cuando las variables de asignación y adopción son binarias. Obtenga el estimador de Wald como el cociente de la diferencia en gasto total promedio entre los hogares asignados a tratamiento y control dividido por la diferencia en la probabilidad de adopción entre los hogares asignados a tratamiento y control.*

Antes que todo importamos la base de datos:
```{r}
dbmarr<- read.csv("C:/DAVE2/CIDE/3 semestre/eps/2 TAREA/crepon_morocco_analysis.csv",
                  encoding = "latin1")
```


Obtenemos estadísticas descriptivas para el grupo tratado y el de control:
```{r} 
formattable(dbmarr%>%group_by(Grupo=treatment)%>%summarise(Promedio=mean(members_resid_bl),Desviación_S=sd(members_resid_bl), Observaciones=n()),col.names = c("Grupo","Promedio", "Desviación Estándar", "Observaciones"), allign=c("c","c","c","c"))
```


Calculamos el numerador para el estimador de Wald:
```{r}
coc<-dbmarr%>%filter(treatment==1)%>%summarise(mean(expense_total))-
dbmarr%>%filter(treatment==0)%>%summarise(mean(expense_total))

```

Ahora computamos el correspondiente denominador:
```{r}
por<-(dbmarr%>%filter(treatment==1& client==1)%>%count()/dbmarr%>%filter(treatment==1)%>%count())-
  (dbmarr%>%filter(treatment==0& client==1)%>%count()/dbmarr%>%filter(treatment==0)%>%count())
```

Finalmente efectuamos el cociente para obtener el estimador de Wald:
```{r}
formattable(coc/por, allign="c", col.names="Estimador de Wald")

```
Podemos crear una función que nos permita calcular el coeficiente de Wald para agilizar el procedimiento:

```{r}
fun_wald <- function (X){
  coc<-X%>%filter(treatment==1)%>%summarise(mean(expense_total))-
  X%>%filter(treatment==0)%>%summarise(mean(expense_total))
  por<-(X%>%filter(treatment==1&    client==1)%>%count()/dbmarr%>%filter(treatment==1)%>%count())-
  (X%>%filter(treatment==0& client==1)%>%count()/dbmarr%>%filter(treatment==0)%>%count())
  wald1=as.numeric(coc/por)
return(wald1)}
```

En esta función será suficiente pasar como argumento la muestra respecto a la cual queremos calcular el estimador de Wald:

```{r}
fun_wald(dbmarr)
```
Notamos que los dos resultados coinciden.



## Inciso B
*Ahora estime por MC2E el efecto de la adopción sobre el gasto total, usando la variable de asignación como instrumento para la adopción. ¿Qué ventaja observa con respecto al estimador de Wald? En R, la función ivreg del paquete AER le permite hacer la estimación de MC2E.*

Estimamos por medio de una regresión MC2E el efecto de la adopción sobre el gasto total utilizando la asignación al tratamiento, aleatorizada, como instrumento para la adopción: 
```{r, message = FALSE, warnings=FALSE, eval=TRUE}
ivreg1<-ivreg(expense_total~client| treatment, data = dbmarr)
stargazer(ivreg1, title="MC2E", align=TRUE, type = "text")
```

Notamos que el estimador asociado a client coincide con el estimador de Wald calculado en el inciso A.

Por medio de la regresión con una variable instrumentales logramos calcular el LATE (Local Average Treatment Effect) del tratamiento. 

Ahora bien, este efecto lo podemos estimar en este caso también por medio de un estimador de Wald. Eso, pero es posible solo porque la regresión es en su forma corta, ósea no hay controles, y tanto $Z$ (asignación al tratamiento) como $D$ (adopción) son binarias. De otra forma la estimación por de Wald sería sesgada e inconsistente.

Otro elemento distintivo de la estimación del efecto por medio de la M2CE es que este método nos arroja también la desviación estándar muestral asociada al estimador que nos permite averiguar la significatividad estadística de este.  

Por lo tanto, las principales ventajas de utilizar el método de variable instrumentales son que podemos controlar por diferentes factores, haciendo nuestra evaluación causal más precisa siendo que vamos purgando el error de eventuales variables omitidas, y evaluar la significatividad de los resultados. Finalmente, las estimaciones resultarían consistentes, aunque hubieran tratamientos intensivos y no binarios. 


## Inciso C
*Estime la forma reducida del efecto de ser asignado al tratamiento sobre gasto total. Comente los resultados, en particular, comente sobre la magnitud y la significancia estadística de la variable treatment. Aquí y en adelante, incluya los siguientes controles en la regresión: members_resid_bl, nadults_resid_bl, head_age_bl, act_livestock_bl, act_business_bl, borrowed_total_bl, members_resid_d_bl, nadults_resid_d_bl, head_age_d_bl, act_livestock_d_bl, act_business_d_bl, borrowed_total_d_bl, ccm_resp_activ, other_resp_activ, ccm_resp_activ_d y other_resp_activ_d. Además, incluya efectos fijos por pareja introduciendo la variable paire como factor. Y finalmente, para realizar inferencia, reporte los errores estándar agrupados a nivel demi_paire usando la función coef_test del paquete clubSandwich.*

La forma reducida (o ITT) es la diferencia en la variable dependiente entre grupos de asignación. Para calcularla tenemos que regresar la variable dependiente sobre la aleatoria (y los controles), en nuestro caso **treatment**:
```{r}
lmr<- lm(expense_total~ treatment+members_resid_bl+ nadults_resid_bl+ head_age_bl+ act_livestock_bl+ act_business_bl+borrowed_total_bl+ members_resid_d_bl+ nadults_resid_d_bl+ head_age_d_bl+ act_livestock_d_bl+ act_business_d_bl+ borrowed_total_d_bl+ ccm_resp_activ+ other_resp_activ+ ccm_resp_activ_d + other_resp_activ_d+ factor(paire) ,data=dbmarr)
```

Reportamos ahora los errores estándar agrupados a nivel demi_paire:
```{r}
coef_test(lmr, vcov = "CR1S", cluster= dbmarr$demi_paire, test="naive-t")[2,]
```

Los resultados muestran que el tratamiento tiene un efecto positivo estadísticamente significativo al $5\%$. Por lo que concierne la magnitud vemos que en promedio los individuos asignados al grupo tratado tienen un gasto de $4057$ unidad de más. 

Analizamos ahora los demás coeficientes:
```{r}
coef_test(lmr, vcov = "CR1S", cluster= dbmarr$demi_paire, test="naive-t")[1:12,]
```

Notamos finalmente que también members_resid_bl, act_livestock_bl, act_business_bl, members_resid_d_bl, ccm_resp_activ y ccm_resp_activ_d resultan significativos con los primeros que tienen un efecto positivo en el gasto total mientras los últimos dos afectan de manera negativa la variable dependiente.		

## Inciso D
*Estime ahora la primera etapa, es decir, estime por MCO el efecto causal de la asignación sobre la adopción. Use los mismos controles que en la parte c. Comente sobre la magnitud, la significancia estadística y la interpretación de la variable treatment en términos del comportamiento de los cumplidores.*

Estimamos la primera etapa:
```{r}
lm1et<- lm(client~ treatment  +members_resid_bl+ nadults_resid_bl+ head_age_bl+ act_livestock_bl+ act_business_bl+borrowed_total_bl+ members_resid_d_bl+ nadults_resid_d_bl+ head_age_d_bl+ act_livestock_d_bl+ act_business_d_bl+ borrowed_total_d_bl+ ccm_resp_activ+ other_resp_activ+ ccm_resp_activ_d + other_resp_activ_d+ factor(paire), data=dbmarr )

coef_test(lm1et, vcov = "CR1S", cluster= dbmarr$demi_paire, test="naive-t")[2,]
```
El coeficiente estimado asociado a treatment representa el efecto causal de la asignación al tratamiento sobre el cumplimiento. Siendo que tratamiento y client en nuestro caso son ambas dummies, el coeficiente de treatment representa la proporción de la población que son cumplidores. 

El coeficiente resulta significativo al $1\%$ y notamos que tiene un efecto positivo, como nos esperábamos, con una magnitud de $0.16719$. Permitiéndonos comprobar la relevancia del instrumento y confirmando la validez de la primera etapa. 

```{r}
lm1et$coeff[2]
```

Podemos notar que hay una diferencia respecto a la proporción que habíamos calculado en el punto A, esto se debe al hecho que añadimos los controles, si hacemos la primera etapa sin estos obtendremos los mismos resultados:

```{r}
lm(client~treatment, dbmarr)$coeff[2]
```



## Inciso E
*Considere la columna 3 del panel A en la Tabla 9 del artículo. Aquí se reporta la estimación por MCO de la relación entre client y gasto total, con los mismos controles y tipo de errores que en c. Replique este resultado. ¿Se puede interpretar de forma causal el coeficiente sobre client?*

```{r}
lmde<- lm(expense_total~ client+members_resid_bl+ nadults_resid_bl+ head_age_bl+ act_livestock_bl+ act_business_bl+borrowed_total_bl+ members_resid_d_bl+ nadults_resid_d_bl+ head_age_d_bl+ act_livestock_d_bl+ act_business_d_bl+ borrowed_total_d_bl+ ccm_resp_activ+ other_resp_activ+ ccm_resp_activ_d + other_resp_activ_d+ factor(paire) ,data=(dbmarr%>%filter(treatment==1)))

coef_test(lmde, vcov = "CR1S", cluster= (dbmarr%>%filter(treatment==1))$demi_paire, test="naive-t")[2,]

```

Calculamos los promedios en gasto total para el grupo de control y el número 6de observaciones con que se evaluó el modelo:
```{r}
cbind(dbmarr%>%filter(treatment==1 & client==0)%>%summarise(Control_Mean=mean(expense_total)),Observation=
nrow(dbmarr%>%filter(treatment==1))) 
```

Podemos notar que obtenemos los mismos resultados reportados en la tabla:

![Table 9 Crépon et al.: the Impact of Microcredit: EVIDENCE FROM MOROCCO](evidencefrommarocco.PNG)

¿Se puede interpretar de forma causal el coeficiente sobre **client**?

No, el estimador asociado con **client** podría ser sesgado dado que la adopción no es aleatoria. Lo que se aleatorizó es la oportunidad de ser client pero, puede ser que el subconjunto que efectivamente adhiere al programa tenga características distintas y peculiares que llevarían a un sesgo de autoselección. 

Además averiguamos en el punto **1.D** que client resulta correlacionada con treatment de forma estadísticamente significativa. Por lo tanto, regresando nada más expense total sobre client y los controles tendremos un problema de endogeneidad dado que no sé incluyó treatment que estará en el error.


## Inciso F
*¿Cuáles son los supuestos econométricos que permiten la estimación del Local Average Treatment Effect (LATE) en el contexto de este problema? Comente sobre la evidencia que respalda el supuesto de que los instrumentos no son débiles en este problema.*

Los dos supuestos principales que nos permiten calcular la estimación del LATE son que:
* RELEVANCIA: cliente y treatment son correlacionados de manera estadísticamente significativa (demostrado en el punto 1.d)
* HEXOGENEIDAD: treatment y el error no son correlacionado, esta condición no se puede comprobar directamente, pero por el diseño aleatorio del tratamiento podemos suponer que se cumpla

Más en general los supuestos que necesitamos para identificar efectos causales con IV:

### 1. Stable Unit Treatment Value Assumption (SUTVA)

Los resultados potenciales de cada individuo no deben ser correlacionados con los de los otros individuos. En nuestro caso significa que la ganancia. En notación matemática, tomando como notación:
* ET= expense total
* T=treatment
* C=client
* i= individuo

Tendremos así:
$$ET(T,C)=ET_i(T_i,C_i)\: \wedge C_i(D)=C_i(D_i)$$

### 2. Asignación aleatoria

La asignación del tratamiento es aleatoria, ósea:
$$P(T=C)=P(T=C') \> \>  \forall\> C,C'$$


Estos primeros dos supuestos nos permiten identificar los efectos causales del aleatorización en el adopción y en los resultados potenciales estimando $ITT_{ET} \> \wedge \> ITT_C$

### 3. Restricción de exclusión

El supuesto de exclusión consiste en:
$$Y(D)=Y(T,C)=Y(T',C) \:\: \forall T,T',C$$
Así podemos escribir:

$$Y_i(1,d)=Y_i(0,d), \:\: d=\{0,1\}$$
Esto significa que resolvemos el problema contrafactual.

### 4. Efecto causal

El efecto causal promedio de T sobre C distinto de cero, ósea: 

$$E(D_i(1)-D_i(0))\neq0$$

Esto fue averiguado en el inciso D

### 5. Monotonicidad

No hay individuos que cuando son asignados no cumplen y no hay personas que cuando no son asignados al tratamiento cumplen, $D_i(1)\geq D_i(0) \:\: \forall i=1, \cdots,N$

Sobre el hecho que el instrumento no sea débil vemos siempre del punto precedente que en la primera etapa el coeficiente resultó estadísticamente significativo con una magnitud estimada que impacta en un aumento de $0.167$ la variable client.

Podemos excluir que el instrumento es debil evaluando el valor F de la regresión de la primera etapa:
```{r}
stargazer(summary(lm1et)$fstatistic, type="text", title="F-test primera etapa")
```
La regla de dedo nos dice que por $F>10$ el instrumento no será débil.

## Inciso G
*Estime el efecto del cumplimiento sobre el gasto total, usando la asignación aleatoria como instrumento del cumplimiento. Es decir, estime el LATE. Use los mismos controles y tipo de errores que en c. Este resultado se reporta en la columna 3 del panel B en la Tabla 9. ¿Cuál es la interpretación del coeficiente de la variable client?*

```{r}
late<- ivreg(expense_total~ client+members_resid_bl+ nadults_resid_bl+ head_age_bl+ act_livestock_bl+ act_business_bl+borrowed_total_bl+ members_resid_d_bl+ nadults_resid_d_bl+ head_age_d_bl+ act_livestock_d_bl+ act_business_d_bl+ borrowed_total_d_bl+ ccm_resp_activ+ other_resp_activ+ ccm_resp_activ_d + other_resp_activ_d+ factor(paire)|treatment +members_resid_bl+ nadults_resid_bl+ head_age_bl+ act_livestock_bl+ act_business_bl+borrowed_total_bl+ members_resid_d_bl+ nadults_resid_d_bl+ head_age_d_bl+ act_livestock_d_bl+ act_business_d_bl+ borrowed_total_d_bl+ ccm_resp_activ+ other_resp_activ+ ccm_resp_activ_d + other_resp_activ_d+ factor(paire) ,data=dbmarr)

coef_test(late, vcov = "CR1S", cluster= dbmarr$demi_paire, test="naive-t")[2,]
```

Calculamos los promedios en gasto total para el grupo de control y el número de observaciones con que se evaluó el modelo:
```{r}
cbind(dbmarr%>%filter(treatment==0)%>%summarise(Control_Mean=mean(expense_total)), Observation=nrow(dbmarr))

```

Podemos notar que logramos replicar los valores obtenidos en el artículo:

![Table 9(B) Crépon et al.: the Impact of Microcredit: EVIDENCE FROM MOROCCO](evidence2.PNG)


El coeficiente asociado a client es el estimador LATE (Local Avarage Treatment Effect) ósea el efecto causal promedio del tratamiento en el conjunto de individuos cuyo estatus de tratamiento fue modificado por la asignación aleatoria, los *compliers*.

# Ejercicio 2
En la Pregunta 1 obtuvo el estimador de Wald para aproximar el efecto de la adopción en el gasto total. Considere dicho cálculo sin controles.

## Inciso A
*Utilice un procedimiento bootstrap a mano para estimar el error estándar del estimador de Wald usando 50 repeticiones. Es decir, debe realizar un remuestreo de los datos originales y para cada muestra obtener el estimador de Wald. Luego, obtenga la desviación estándar de los 50 estadísticos calculados. Utilice una semilla para poder replicar sus resultados.*

Utilizamos la función precedentemente construida para calcular el estimador de Wald de 50 repeticiones de un remuestreo con reemplazo:  
```{r}  
set.seed(126)
data_wald <- tibble(num = 1:50) %>% 
    group_by(num) %>%
    mutate(wald  = fun_wald(sample_n(dbmarr,size= nrow(dbmarr),replace = TRUE)))
```
Obtenemos la desviación estandard por medio de la función dedicada:
```{r}
sd(data_wald$wald)
```
Y a manita:
```{r}
sqrt(sum((data_wald$wald-mean(data_wald$wald))**2)/(nrow(data_wald)-1))
```
Dado que se obtuvieron los mismos resultados utilizaremos en adelante la función de R (sd).

## Inciso B
*Reemplace la semilla de la parte a. por una nueva semilla y estime nuevamente el error estándar del estimador de Wald con 50 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.*

```{r sample 50}  
set.seed(300)
data_wald2 <- tibble(num = 1:50) %>% 
    group_by(num) %>%
    mutate(wald  = fun_wald(sample_n(dbmarr,size= nrow(dbmarr),replace = TRUE)))
```
Obtenemos la desviación estandard:
```{r}
sd(data_wald2$wald)
```
Notamos que el valor, aunque resulte bastante parecido en magnitud (la diferencia es inferior al 2%) no resulta igual:

```{r}
(sd(data_wald$wald)-sd(data_wald2$wald))/sd(data_wald2$wald)
```
Esto se debe al hecho que el muestreo con remplazo es aleatorio y cambiando la semilla ya no arrojará los mismos resultados que en el inciso A.

## Inciso C
*Regrese el valor de la semilla al usado en a. y estime nuevamente el error estándar del estimador de Wald, esta vez usando 1000 repeticiones. Comente sobre la diferencia entre este error estándar y el de la parte a.*

```{r sample 1000}  
set.seed(126)
data_wald3 <- tibble(num = 1:1000) %>% 
    group_by(num) %>%
    mutate(wald  = fun_wald(sample_n(dbmarr,size= nrow(dbmarr),replace = TRUE)))
```
Obtenemos la desviación estandard:

```{r}
sd(data_wald3$wald)
```
Siendo un promedio muestral la teoría del límite central nos dice que por $N \rightarrow \infty$ obtendremos un estimador consistente. Efectivamente aumentando el número de repeticiones obtenemos un valor más cercano al que obtuvimos en el inciso **1.B** ($12683.7$). 

# Ejercicio 3
*Se propone evaluar el efecto de usar cubrebocas en la tasa de transmisión del covid-19 en el país A, que está compuesto por cientos de islas y donde cada isla es una ciudad. Al inicio de la epidemia, se prohibieron los viajes entre islas. Se dispone de datos de la tasa de fatalidad en varias ciudades en los momentos t=0 y t=1. Entre el periodo 0 y el 1 se sabe que en un subconjunto de cinco ciudades se ordenó el uso obligatorio del cubrebocas.*

## Inciso A
*¿Cómo evaluar los resultados de ordenar el uso del cubrebocas por medio de diferencia en diferencias? ¿Cómo seleccionaría al grupo de ciudades que se usarían para llevar a cabo esta evaluación?*

Para poder medir el impacto del uso del cubrebocas en la tasa de fatalidad podemos utilizar un método de Diferencias en Diferencias. En nuestro caso tenemos las tasas de fatalidad para varias ciudades en dos puntos en el tiempo $t_0$ y $t_1$. Un primer método burdo para efectuar el análisis sería la siguiente DID:

$$\delta_{DiD1}=(\bar Y_{5,post}-\bar Y_{5,pre})- (\bar Y_{95,post}-\bar Y_{95,pre})$$
En este caso el efecto del uso de cubrebocas será dado por $\delta_{DiD1}$, que nos indicará la diferencia entre los cambios en la tasas de mortalidad.

Con mucha probabilidad las características de algunas de las 95 islas donde no se implementó el tratamiento tendrán características muy distintas respecto a las 5 donde si se empezó a utilizar el cubrebocas, por lo tanto, el supuesto de tendencias paralela se violaría. En caso que los únicos datos que poseemos relativos a las islas  son las tasas de fatalidad podemos refinar nuestra análisis escogiendo un subconjunto de islas $A$ donde haya ciudades con tasa de mortalidad similares en $t_0$. Esperaríamos así de respectar el supuesto de tendencias paralelas y obviar al problema de tendencias exponenciales. A este punto podemos utilizar los promedios de las tasas de mortalidad como hecho precedentemente. Siendo que en el subconjunto $A$ tendremos islas similares a la del grupo tratado $\bar Y_{5,pre} \approx Y_{A,pre}	$. Y el efecto en la tasa de mortalidad será dado por:

$$\delta_{DiD1}=(\bar Y_{5,post}-\bar Y_{5,pre})- (\bar Y_{A,post}-\bar Y_{A,pre})\approx\bar Y_{5,post}-\bar Y_{A,post}$$
En lugar de tomar el promedio podríamos hacer un DiD para cada isla del grupo tratado identificando 5 cluster de islas $A_1,A_2,A_3,A_4,A_5$ y promediar los DiD encontrados: $\frac{\sum_{i=1}^5 \delta_{DID_i}}{5}$, esto nos permitiría una estimación más acurada. 

Si tuviéramos características observables relevantes podríamos utilizarlas para escoger los subconjuntos precedentemente identificados en lugar de usar la tasa de mortalidad.

Los resultados obtenidos podrían ser calculados también por medio de una regresión:

$$y_{dt}=\alpha+\beta T_d+\gamma POST_t + \delta_{r,DID}(T_d\times POST_t)+e_{dt}$$

Otro metodo podría ser lo de intrpoducir efectos fijos por isla y efectuar una regresión:

$$y_{st}=\alpha+\delta_{DID}T_{st}+\sum_k\beta_k ISLA_{ks}+\sum_j \gamma_j TIEMPO_{jt}+e_{st}$$
Esto dependería de los datos que tendríamos a disposición.

Finalmente podríamos crear un control sintético para cada isla y evaluar así el impacto aunque este no es un método DID.

## Inciso B
*¿Cuáles son los supuestos sobre los que recae la estrategia de evaluación por diferencia en diferencias? ¿Qué factores podrían amenazar el uso de esta estrategia para evaluar el efecto de la intervención?*

El supuesto fundamental para la evaluación por medio de una DID es el de tendencias comunes, ósea que en ausencia del tratamiento la evolución de la tasa de letalidad del virus se habría comportado igual en la isla tratada y las que representan su contrafactual. Siendo qué tenemos solo dos puntos en el tiempo no podemos comprobar esta hipótesis. 

Muchos factores pueden amenazar el uso de esta estrategia para evaluar el efecto de la intervención, entre estos:
* Si hay algún evento, que no podemos observar, que cambia las trayectorias de la mortalidad en el grupo tratado independientemente de la política publica implementada nos llevaría a una subestimación o una sobre estimación.
* algún evento que cambie la trayectoria de la mortalidad en el grupo de control, que no puede ser atribuido a la evolución "natural" del virus nos llevaría a sesgar nuestra estimación. 
* Sesgo de selección respecto a alguna característica inobservable. 
* Violación de los supuestos de tendencias paralelas pre-intervención.
* Siendo que no conocemos los momentos en que fueron implementadas las políticas podríamos incurrir en estimaciones imprecisas.
* Los efectos de las intervenciones tienen efectos tardíos que no pertenecen a la ventana de tiempo analizada.


## Inciso C
*Suponga que un archipiélago vecino, el país B, también conformado por 1000 ciudades-isla implementa un programa de entrega de cubrebocas. El país solo puede entregar cubrebocas en 100 de las ciudades, las cuales serán escogidas en una lotería pública con un generador de números aleatorios. Expliqué cómo usaría inferencia por aleatorización (randomization inference) para estimar el impacto de la intervención en la tasa de fatalidad. Describa con detalle el procedimiento seguido y cómo juzgaría la significancia estadística de las diferencias que observe.*

Para evaluar el impacto de la intervención de política publica por medio de randomization inferrence podemos seguir los siguientes pasos:

1. Creamos un estadístico para evaluar nuestra hipótesis, podemos utilizar una prueba de Fisher sharp con hipótesis nula que el tratamiento no haya efecto, uno podría ser una diferencia de media como la que vimos en clase:

$$C(T)=\frac{\sum_{i=1}^{1000} T_i M_i}{100}-\frac{\sum_{i=1}^{1000} (1-T_i) M_i}{900}$$
Con $M_i$ es la tasa de mortalidad en la isla $i$.

2. Asignamos aleatoriamente el tratamiento falso utilizando el mismo procedimiento con que fue asignado el original, ósea por medio de una Lotería con un generador de números aleatorios.

3. Calculamos el relativo estadístico utilizado repitiendo el proceso N veces, con $N>1000$

4. Calculamos el p-value tomando el promedio de las veces donde el estadístico original resultó mayor del valor de los estadísticos "falsos". Ósea: 
$$p=\frac{1}{N}\sum_{i=1}^{N} I \left(C(T_{i})\geq C(t)\right)$$
Con $I=1$ cuando se satisface $C(T_{i})\geq C(t)$

5. Si queremos un nivel de significancia al 5% rechazamos la hipótesis nula si $p-value\leq0.005$. En este caso el programa de distribución de cubrebocas hará obtenido un impacto en la tasa de mortalidad de la enfermedad. 



# Ejercicio 4
*Considere nuevamente la base STAR_public_use.csv usada en la Tarea 1. del artículo Angrist, Lang y Oreopoulos (2009). En esta pregunta nos concentraremos en los efectos de la intervención en el año 2, mostrados en la columna (4) de la Tabla 6, sobre dos variables, el promedio de calificaciones gpa_year2 y los créditos completados credits_earned2.*

*El propósito de esta pregunta es mostrar la función de los z-scores en el análisis de efectos de tratamiento. De nuevo, puede quedarse solo con las observaciones que tienen noshow igual a 0. Antes de comenzar su análisis, sustituya por NA los valores en credits_earned2 para aquellas observaciones que tienen NA en la variable prob_year1.*

Importamos el DB:
```{r echo = T, results = 'hide'}
dbstar <- as_tibble(read.csv("C:/DAVE2/CIDE/3 semestre/eps/1 TAREA/STAR_public_use.csv"))
```

Modificamos el DB como requerido en el ejercicio:
```{r}
dbstar1 <- dbstar %>% mutate(
   credits_earned2= ifelse (is.na(prob_year1), NA ,  credits_earned2))%>%
  filter(noshow == 0)%>%select(credits_earned2,GPA_year2,prob_year1, ssp, sfp, sfsp, sex, mtongue, hsgroup, numcourses_nov1,lastmin,mom_edn,dad_edn,control)%>%
  filter(mtongue!="" 
         &hsgroup!=""
         &numcourses_nov1!=""
         &sex!=""
         &lastmin!=""
         &mom_edn!=""
         &dad_edn!="")%>%drop_na(credits_earned2)
```

## Inciso A
*Para tener un punto de comparación, estime la ecuación del efecto de tratamiento para credits_earned2 usando la misma especificación que en la pregunta 5 de la Tarea 1. Use también errores robustos. Deberá poder replicar los coeficientes y errores estándar del panel D, columna (4). ¿Cómo se interpretan el coeficiente sobre la variable ssp?*

```{r}
lmdbstar <-lm(credits_earned2 ~  ssp + sfp + sfsp + relevel(factor(sex), ref="M") + factor(mtongue) + factor(hsgroup) + factor(numcourses_nov1) + factor(lastmin) + factor(mom_edn) + factor(dad_edn) , data = dbstar1)
```

Obtenemos los errores robustos:
```{r}
robustos1 <-coeftest(lmdbstar, vcov=vcovHC(lmdbstar, "HC1"))
stargazer(robustos1[1:4,], type="text") 
```

El coeficiente de SSP mide el impacto respecto a la variable dependiente, ósea el número de créditos obtenidos en el segundo año para las personas que recibieron el programa SSP respecto a los que no recibieron ningún programa (grupo de control). en nuestro caso el coeficiente resulta no significativo y por lo tanto no podemos detectar ningún efecto del tratamiento en los créditos adquiridos en el segundo año. 

## Inciso B
*Genere un z-score para la variable credits_earned2 al que llame credits_earned2_sd. Para ello, calcule la media y desviación estándar de credits_earned2 para el grupo de control y luego genere credits_earned2_sd restándole a credits_earned2 la media obtenida y dividiendo esta diferencia por la desviación estándar obtenida. Compruebe que si calcula la media y la desviación estándar de credits_earned2_sd, en el grupo de control estas deberían ser 0 y 1, respectivamente.*

Generamos el z-score para la variable **credit_earned2**:
```{r}
dbstar3<-dbstar1%>%mutate(credits_earned2_sd2=((credits_earned2-mean(subset(dbstar1, control==1)$credits_earned2))/sd(subset(dbstar1, control==1)$credits_earned2)))
```

Averiguamos que efectivamente obtuvimos un z-score:
```{r}
dbstar3%>%summarise(mean_z_score=mean(subset(dbstar3, control==1)$credits_earned2_sd2), sd_z_score=sd(subset(dbstar3, control==1)$credits_earned2_sd2))
  
```
Efectivamente la media en el grupo de control de la nueva variable es $0$ y la desviación estándar es $1$.

## Inciso C
*Realice la misma estimación que en la parte a., pero ahora use como variable dependiente credits_earned2_sd. ¿Cómo se interpreta el coeficiente sobre ssp? ¿Qué es diferente y qué es igual entre los resultados obtenidos en esta parte y los obtenidos en la parte a.?*

Efectuamos la regresión con la nueva variable dependiente:
```{r}
lmdbstar2 <-lm(credits_earned2_sd2 ~  ssp + sfp + sfsp + relevel(factor(sex), ref="M") + factor(mtongue) + factor(hsgroup) + factor(numcourses_nov1) + factor(lastmin) + factor(mom_edn) + factor(dad_edn) , data = dbstar3)
```

Obtenemos los errores robustos:
```{r}
robustos2<-coeftest(lmdbstar2, vcov=vcovHC(lmdbstar2, "HC1"))
robustos2[1:4,]
```

El coeficiente obtenido será el efecto del tratamiento (SSP) medidos en desviaciones estándar con respecto a la media del grupo de control.



Comparando los resultados de los dos modelos (con y sin errores robustos):
```{r}
c<-list(lmdbstar,lmdbstar2)
        
modelsummary(c, type = "text" )
stargazer(robustos1, robustos2, type = "text" )
```

Notamos que las magnitudes de los efectos cambian, esto se debe al hecho que en el primer modelo estos vienen medidos en número de créditos adquiridos demás o de menos respecto al grupo de control mientras en el modelo con variable dependiente z-score se mide en número de desviaciones estándar. De igual manera cambian también la magnitud de los errores estándar. Notamos pero que no cambia el signo de los efectos, la significatividad estadística de los coeficientes obtenidos (el t-value no cambia) y la bondad de ajuste de los modelos.    

## Inciso D
*Ahora realizaremos un índice de mejora en educación, al agregar los resultados de estos dos indicadores en una sola variable, como se describe en Banerjee et al. (2015). Para ello, primero genere gpa_year2_sd, que será la versión estandarizada de gpa_year2, siguiendo el mismo procedimiento que en la parte b. En seguida, genere una nueva variable llamada promedio_vars, que será el promedio de credits_earned2_sd y gpa_year2_sd. Luego, calcule la media y la desviación estándar de promedio_vars en el grupo de control. Finalmente, genere una nueva variable promedio_vars_sd restándole a promedio_vars la media antes calculada y dividiendo esta diferencia por la desviación estándar antes calculada. Muestre que la variable promedio_vars_sd tiene media 0 y desviación estándar 1 en el grupo de control.*

Obtenemos el Z-score para **gpa_year2_sd**:
```{r}
dbstar4<-dbstar3%>%mutate(GPA_year2_sd2=(( GPA_year2-mean(subset(dbstar3, control==1)$GPA_year2, na.rm=T))/sd(subset(dbstar3, control==1)$GPA_year2, na.rm=T)))
```

Averiguamos que efectivamente obtuvimos un z-score:
```{r}
dbstar4%>%summarise(mean_z_score=mean(subset(dbstar4, control==1)$GPA_year2_sd2, na.rm=T), sd_z_score=sd(subset(dbstar4, control==1)$GPA_year2_sd2, na.rm=T))

```

Creamos la variable **promedio_vars**:
```{r}
dbstar4<-dbstar4%>%mutate(promedio_vars=(credits_earned2_sd2+GPA_year2_sd2)/2)
```

Ahora calculamos media y varianza para promedio vars en el grupo de control:
```{r}
dbstar4%>%summarise(mean_prom_var=mean(subset(dbstar4, control==1)$promedio_vars, na.rm=T), sd_prom_var=sd(subset(dbstar4, control==1)$promedio_vars, na.rm=T))
```

Ahora obtenemos el z-score para **promedio_vars**:
```{r}
dbstar5<-dbstar4%>%mutate(promedio_vars_sd=(( promedio_vars-mean(subset(dbstar4, control==1)$promedio_vars, na.rm=T))/sd(subset(dbstar4, control==1)$promedio_vars, na.rm=T)))
```

Averiguamos que efectivamente obtuvimos un z-score en el grupo de cotnrol en la variable en examen:
```{r}
dbstar5%>%summarise(mean_prom_var_sd=mean(subset(dbstar5, control==1)$promedio_vars_sd, na.rm=T), sd_prom_var=sd(subset(dbstar5, control==1)$promedio_vars_sd, na.rm=T))
```
Efectivamente hemos obtenido el resultado esperado.

## Inciso E
*Estime ahora el efecto de tratamiento sobre promedio_vars_sd, siguiendo la misma especificación econométrica que en la parte a. y usando errores robustos. ¿Qué concluye?*

```{r}
lmdpromvar <-lm(promedio_vars_sd ~  ssp + sfp + sfsp + relevel(factor(sex), ref="M") + factor(mtongue) + factor(hsgroup) + factor(numcourses_nov1) + factor(lastmin) + factor(mom_edn) + factor(dad_edn) , data = dbstar5)
```

Obtenemos los errores robustos:
```{r}
robustosvar <-coeftest(lmdpromvar, vcov=vcovHC(lmdpromvar, "HC1"))
robustosvar[1:4,]
```
Los resultados obtenidos muestran que los tratamientos no tienen efectos estadísticamente significativos sobre el índice creado. Esto fue hecho para agregar dos medidas distintas de rendimiento escolástico. Por lo tanto, podemos pensar que los programas implementados no hayan mejorados las performance conjunta de los estudiantes a mediano plazo (al final del segundo año).  


# Ejercicio 5
*Considere los valores p del archivo pvalues.csv. Cada valor pi está asociado a una prueba de hipótesis i. La variable familia denota tres grupos de hipótesis sobre las cuales estamos interesados en hacer correcciones de múltiples hipótesis. La investigación en cuestión emplea $\alpha=0.05$.*

Cargamos el DB:
```{r}
dbpv<-read.csv("C:/DAVE2/CIDE/3 semestre/eps/2 TAREA/pvalues.csv")
```

Analizamos la estructura:
```{r}
str(dbpv)
```

## Inciso A
*Para cada una de las pruebas de hipótesis, genere un cuadro como el que se presenta a continuación y diga si se rechaza o no la hipótesis nula, bajo los siguientes criterios:*

Inicializamos nuestro coeficiente de significancia deseada:
```{r}
alpha<-0.05
```


Creamos la tabla que requerimos, en el desarrollo se calculó también la corrección de Hochber pero se seleccionarán solo las columnas pedidas en el ejercicio con los respectivos p-values:
```{r}
word_formatter <- formatter("span",
  style = x ~ style(color = ifelse(x == "Rechazo", "green", "red")))

formattable(dbpv%>%arrange(desc(-p))%>%arrange(desc(-familia))%>%
  group_by(familia)%>%mutate(indexf=row_number())%>%ungroup()%>%
  group_by(familia)%>%mutate(countfam=n())%>%
  mutate(hipotesis_sin_correccion = if_else(p<=alpha, "Rechazo", "No rechazo"))%>%
  mutate(alphabon=alpha/countfam)%>%
  mutate(hipotesis_bonf = if_else(p<=alphabon, "Rechazo", "No rechazo"))%>%
  #hemos ordenado el db de más pequeño a más grande en p-values adentro de las    familais
  mutate(alphahoch=alpha/(countfam-indexf+1))%>%
  mutate(hipotesis_hochberg = if_else(p<=alphahoch, "Rechazo", "No rechazo"))%>%
  mutate(alphaBandH=alpha*indexf/countfam)%>%
  mutate(hipotesis_BandH = if_else(p<=alphaBandH, "Rechazo", "No rechazo"))%>%select(hipotesis,p,familia,hipotesis_sin_correccion,alphabon,hipotesis_bonf,alphaBandH,hipotesis_BandH), col.names=c("Hípotesis","p-value","Familia","Hípotesis sin correccion","Alpha Bonferroni","Corrigiendo  dentro de la familia usando el método de Bonferroni","Alpha de Benjamini y Hocheberg", "Corrigiendo por la tasa de falso descubrimiento dentro de la familia con el método de B&H"), allign=c("c","c","c","c","c","c","c","c"), list('p'= color_bar("lightpink"),'alphabon'= color_bar("lightgreen"),'alphaBandH'= color_bar("lightblue"),'hipotesis_sin_correccion'=word_formatter, "hipotesis_bonf"=word_formatter,"hipotesis_BandH"=word_formatter ))
```
## Inciso B
*Suponga que encuentra buenas razones conceptuales para afirmar que las familias 2 y 3 deben ser consideraras una sola familia. Tendríamos ahora solo dos familias, la familia 1 original y una nueva familia numerada como 4, como se indica en la variable familia_corregida. ¿Cómo cambian sus conclusiones respecto a la parte a. de esta pregunta? Genere un nuevo cuadro con esta redefinición.*



```{r}
dbpv2<-dbpv

formattable(dbpv2%>%arrange(desc(-p))%>%arrange(desc(-familia_corregida))%>%
  group_by(familia_corregida)%>%mutate(indexf=row_number())%>%ungroup()%>%
  group_by(familia_corregida)%>%mutate(countfam=n())%>%
  mutate(hipotesis_sin_correccion = if_else(p<=alpha, "Rechazo", "No rechazo"))%>%
  mutate(alphabon=alpha/countfam)%>%
  mutate(hipotesis_bonf = if_else(p<=alphabon, "Rechazo", "No rechazo"))%>%
  #hemos ordenado el db de más pequeño a más grande en p-values adentro de las    familais
  mutate(alphahoch=alpha/(countfam-indexf+1))%>%
  mutate(hipotesis_hochberg = if_else(p<=alphahoch, "Rechazo", "No rechazo"))%>%
  mutate(alphaBandH=alpha*indexf/countfam)%>%
  mutate(hipotesis_BandH = if_else(p<=alphaBandH, "Rechazo", "No rechazo"))%>%select(hipotesis,p,familia_corregida,hipotesis_sin_correccion,alphabon,hipotesis_bonf,alphaBandH,hipotesis_BandH), col.names=c("Hípotesis","p-value","Familia Corregida","Hípotesis sin correccion","Alpha Bonferroni","Corrigiendo  dentro de la familia usando el método de Bonferroni","Alpha de Benjamini y Hocheberg", "Corrigiendo por la tasa de falso descubrimiento dentro de la familia con el método de B&H"), allign=c("c","c","c","c","c","c","c","c"), list('p'= proportion_bar("lightpink"),'alphabon'= proportion_bar("lightgreen"),'alphaBandH'= proportion_bar("lightblue"),'hipotesis_sin_correccion'=word_formatter, "hipotesis_bonf"=word_formatter,"hipotesis_BandH"=word_formatter ))
```
Podemos notar que con el agrupamiento de las familias no determina cambios en las hipótesis rechazadas con el método sin correcciones y con Bonferroni. Por lo tanto, no hay diferencia en la tasa de error por familia, ósea la probabilidad de cometer al menos un error tipo I. De otro lado con el método de Benjamini y Hocheberg controlamos la tasa de falso descubrimiento y en este caso con 4 familias distintas rechazamos 7 hipótesis mientras agrupando rechazamos solo 5. Si hay una buena explicación teórica para juntar las familias, esto nos permitirá incurrir en menos falsos positivos eliminando coeficientes que antes se consideraban significativos estadísticamente.

## Inciso C
*Suponga que su asistente de investigación olvidó el concepto de familia y realiza las correcciones por pruebas de múltiples hipótesis ignorando las familias. ¿Qué concluiría en este caso? Genere un nuevo cuadro bajo esta circunstancia. Comente sobre la diferencia en las conclusiones entre las partes b. y c.*

```{r}
dbpv3<-dbpv

formattable(dbpv3%>%arrange(desc(-p))%>%
  mutate(indexf=row_number())%>%
  mutate(countfam=n())%>%
  mutate(hipotesis_sin_correccion = if_else(p<=alpha, "Rechazo", "No rechazo"))%>%
  mutate(alphabon=alpha/countfam)%>%
  mutate(hipotesis_bonf = if_else(p<=alphabon, "Rechazo", "No rechazo"))%>%
  #hemos ordenado el db de más pequeño a más grande en p-values adentro de las    familais
  mutate(alphahoch=alpha/(countfam-indexf+1))%>%
  mutate(hipotesis_hochberg = if_else(p<=alphahoch, "Rechazo", "No rechazo"))%>%
  mutate(alphaBandH=alpha*indexf/countfam)%>%
  mutate(hipotesis_BandH = if_else(p<=alphaBandH, "Rechazo", "No rechazo"))%>%select(hipotesis,p,hipotesis_sin_correccion,alphabon,hipotesis_bonf,alphaBandH,hipotesis_BandH), col.names=c("Hípotesis","p-value","Hípotesis sin correccion","Alpha Bonferroni","Corrigiendo  dentro de la familia usando el método de Bonferroni","Alpha de Benjamini y Hocheberg", "Corrigiendo por la tasa de falso descubrimiento dentro de la familia con el método de B&H"), allign=c("c","c","c","c","c","c","c"), list('p'= color_bar("lightpink"),'alphabon'= color_bar("lightgreen"),'alphaBandH'= color_bar("lightblue"),'hipotesis_sin_correccion'=word_formatter, "hipotesis_bonf"=word_formatter,"hipotesis_BandH"=word_formatter ))
```
Podemos ver que en este caso el número de hipótesis rechazados con el modelo sin correcciones y con el de Benjamini y Hocheberg no cambia. Por lo que concierne las hipótesis rechazadas con el $\alpha$ sin correcciones nos esperábamos la invarianza en los tres casos siendo que la metodología de rechazo es independiente del número de familias. En el método de Benjamini y Hocheberg se observó una disminución de los rechazos ya desde el primer agrupamiento, aunque en este último no hubo cambio, aunque el control de la tasa de falso descubrimientos se volvió más estricta. Finalmente vemos como con el método de Bonferroni ahora rechazamos solo 3 hipótesis mientras antes eran 4. Si este último agrupamiento fue hecho por error y no tiene una justificación teórica el riesgo es rechazar hipótesis demás resultando así demasiados conservadores.

